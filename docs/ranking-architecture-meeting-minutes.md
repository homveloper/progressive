# 회의록: 분산 랭킹 시스템 아키텍처 설계

- **일시**: 2025년 8월 9일
- **참석자**: User, Gemini
- **주요 안건**: 분산 환경에서 1분마다 갱신되는 랭킹 정보를 안정적이고 효율적으로 캐싱하기 위한 최적의 아키텍처 설계

---

## 1. 논의 과정

### 1.1. 초기 요구사항 정의
- 100개 이상의 그룹, 각 그룹에 100명 이상의 사용자가 존재.
- 1분마다 각 그룹의 상위 100위 랭킹을 DB에서 조회하여 Redis에 캐싱 필요.
- 2대 이상의 서버로 구성된 분산 환경에서 안정적으로 동작해야 함.

### 1.2. 아키텍처 패턴 탐색 및 비교
다양한 분산 처리 패턴의 장단점을 비교하며 논의를 시작함.

- **아키텍처 1: 샤딩된 잠금 패턴 (경쟁 기반)**
  - **개요**: 모든 서버가 각 그룹별로 개별 잠금을 획득하기 위해 경쟁하는 가장 단순한 방식.
  - **결론**: 구현은 간단하지만, 그룹 수가 많아지면 잠금 경쟁 비용이 커져 비효율적.

- **아키텍처 2: 사전 캐싱 패턴 (큐 기반)**
  - **개요**: '생성자'가 처리할 작업을 큐에 넣고, '소비자(작업자)'들이 큐에서 작업을 꺼내 병렬 처리하는 방식. `go-asynq`와 같은 전문 라이브러리 활용 제안.
  - **결론**: 안정성과 확장성이 높고, 'Dirty Set', '배치 처리' 등 고급 최적화 적용에 용이. 프로덕션급 시스템에 적합.

- **아키텍처 3: 조회 시점 캐싱 패턴 (On-Demand)**
  - **개요**: 미리 캐시를 만들지 않고, 사용자 요청 시점에 캐시를 확인하고 없으면 DB에서 생성하는 방식.
  - **결론**: 요청이 없는 데이터는 캐싱하지 않아 자원 효율성이 높지만, 최초 요청자에 대한 응답 지연과 캐시 스탬피드 위험 존재.

### 1.3. '조회 시점 캐싱' 심층 분석
'조회 시점 캐싱'의 단점을 극복하고 장점을 활용하기 위한 방안을 집중적으로 논의함.

- **DB 성능의 중요성**: DB 조회 속도(Revalidation 시간)가 10ms 이내로 매우 빠르다면, 최초 요청자의 지연 문제가 거의 사라져 '조회 시점 캐싱'의 매력도가 크게 상승함을 확인.

- **Stale-While-Revalidate (SWR) 전략**: 캐시 스탬피드와 응답 지연 문제를 해결하기 위해, 오래된(Stale) 데이터를 먼저 보여주면서 백그라운드에서 캐시를 갱신하는 SWR 전략을 도입.

- **사용자 경험(UX) 문제 및 해결 방안**: SWR 적용 시, 너무 오래된 데이터를 본 사용자가 데이터의 갑작스러운 변경에 혼란을 겪을 수 있는 문제를 제기. 이에 대한 두 가지 해결책을 논의함.
  1.  **UI/UX를 통한 상태 알림**: API가 데이터와 함께 캐시 상태(`FRESH`/`STALE`)를 반환하여, 프론트엔드에서 '업데이트 중'이라는 시각적 피드백을 주는 방식.
  2.  **최대 허용 시간(Max-Age) 설정**: 특정 시간 이상 지난 데이터는 'Stale'이 아닌 'Miss'로 간주하여, 사용자를 기다리게 하더라도 반드시 신선한 데이터를 보여주는 방식.

### 1.4. 점진적 아키텍처 개선 전략 수립
최종적으로, 위 논의들을 종합하여 서비스의 성장 단계에 따라 아키텍처를 진화시키는 현실적인 로드맵을 수립함.

- **Phase 1 (초기)**: DB 성능에 자신 있다면, 가장 단순한 **'조회 시점 캐싱 + 분산 잠금'**으로 시작하여 개발 속도와 효율을 확보한다.
- **Phase 2 (성능 저하 시)**: DB 응답이 느려지기 시작하면, 백엔드 변경 없이 **'SWR + UI 상태 알림'** 패턴을 도입하여 사용자 경험을 방어한다.
- **Phase 3 (근본적 확장)**: 트래픽이 폭증하여 근본적인 분리가 필요해지면, **'사전 캐싱 (큐 기반)'** 아키텍처로 전환하여 읽기와 쓰기를 완전히 분리한다.

---

## 2. 결정 사항

- **최종 아키텍처 전략**: **점진적 개선 전략**을 채택하기로 결정함.
  - **초기 단계**에서는 DB 성능을 신뢰하고 **'조회 시점 캐싱(On-Demand) + 분산 잠금'** 아키텍처로 단순하고 효율적으로 구현한다.
  - 서비스의 성장과 실제 성능 지표 변화에 따라, 필요시 **'SWR + UI 피드백'**을 도입하고, 궁극적으로는 **'사전 캐싱(큐 기반)'** 아키텍처로 전환할 수 있는 장기적인 로드맵을 염두에 두고 개발을 진행한다.

- **문서화**: 논의된 3가지 주요 아키텍처(샤딩된 잠금, 사전 캐싱, 조회 시점 캐싱)의 개요, 장단점, Mermaid 다이어그램을 포함한 문서를 `docs/architecture-comparison.md`에 저장하여 자산으로 남긴다.